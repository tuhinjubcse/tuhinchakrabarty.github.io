## Tuhin Chakrabarty

![Image](images/pic.jpg)

## About me
I am from Columbia Natural Language Processing group ,fortunate to be advised by my amazing advisors <a href="http://www.cs.columbia.edu/~kathy/" title="Title"> Professor Kathleen McKeown </a>  and  <a href="http://www.cs.columbia.edu/~smara/" title="Title"> Professor Smaranda Muresan </a> and mentor <a href="http://www.cs.columbia.edu/~chidey/" title="Title"> Christopher Hidey  </a> .I am highly interested in Controllable Creative Text Generation, CommonSense Reasoning , Argument Mining, Dialogue Understanding, Discourse and Pragmatics, Textual Inference ,Modeling Implicit Semantics & Transfer learning for NLP. Prior to joining Grad school I was an engineer at UBER and Amazon.
I am also acting as a research consultant at <a href="https://factmata.com" title="Title"> Factmata </a> where I will be mostly involved in using NLP techniques to battle misinformation

## Research Focus

My current research involves incorporating commonsense for natural language understanding and NLG. In the past I have focussed on building better models for literal and figurative language focusing particularly on stylistics/ rhetoric, and semantics.(Ex: argumentation).Argument Mining is a moderately challenging task and argument annotation for supervised learning is often expensive and unsuitable for crowdsourcing.My research tries to alleviate this problem by  collecting weakly labeled data similar to the task of interest from Social Media. 
Read <a href="http://arg.tech/~chris/acl2019tut/argmining-tut-v4.pdf" title="Title"> ArgMining-tutorial@ACL2019 </a> where they mention why Argument mining ( and more so Arg Mining in dialogue) is a very hard task.



Yes Pre-trained models have proved their efficacy in variety of tasks, but how can we improve over them? For tasks where the language is disparately different from pretraining corpus , can we benefit by fine tuning on task of interest? Read my <b>NAACL 2019</b> and <b>EMNLP 2019</b> paper which tries to answer these questions.

I have found new interest in developing computational models for Fact Checking.With the plethora of information available on the internet we need models to verify these. Typically a fact checking pipeline involves robust Information Retrieval and smart Natural Language Inference.Also how can we build robust fact checking models without overfitting on a dataset. How can we create adversarial examples to break models.Read our papers on fact checking to know more about the challenges and how we solve them.

Currently , I am working on computational methods to incorporate machine commonsense or pragmatics (Speaker intent) in creative text generation (for example sarcasm)

## Some Trivia
I took <br />
- COMS 4705(Natural Language Processing) with Professor Michael Collins in Fall 2017 and finished with an A <br />
- COMS E6998(NLP in Context : Computational Models of Social Meaning) with Smaranda Muresan in Spring 2018 and topped the class with an A+ (The course resulted in a ACL Abusive Langugage workshop long paper) <br />
- I spent my summers at Amazon Alexa, Natural Language Understanding Group in Boston  as an Applied  Scientist Intern

## CONFERENCE HIGHLIGHTS 

<p>ACL 2019 : <a href="https://www.cs.columbia.edu/2019/cs-papers-accepted-to-acl-2019/" title="Title"> Check Here </a></p>
<p>EMNLP 2018 : <a href="https://www.cs.columbia.edu/2019/emnlp-2018/" title="Title"> Check Here </a></p>
<p>NAACL 2019 : <a href="https://www.cs.columbia.edu/2019/research-by-spoken-language-and-nlp-groups-at-naacl-2019/
" title="Title"> Check Here </a></p>

## UPDATES
I'll be spending some time at <a href="https://www.cs.jhu.edu/~npeng/group.html" title="Title"> PLUS Lab </a> at USC, ISI,starting August 2019 working on NLP related problems.I am fortunate to be advised by <a href="https://www.cs.jhu.edu/~npeng/" title="Title"> Professor Violet Peng </a>

Oral talks at EMNLP 2019 , Main Conference and FEVER worksop

## PUBLICATIONS

## DISCOURSE AND DIALOGUE
<p> 1) <b> AMPERSAND: Argument Mining for PERSuAsive oNline Discussions </b> <br>
  In Proceedings of EMNLP 2019 ,HongKong [TO APPEAR] ORAL PRESENTATION (Acceptance Rate Oral : 7.9% [230 out of 2877 submitted papers])<br>
  Poster at Natural Language, Dialog, and Speech (NDS) Symposium , New York Academy of Sciences <br>
 <b> Tuhin Chakrabarty </b>, Christopher Hidey, Smaranda Muresan, Kathy McKeown and Alyssa Hwang .
 <a href="https://www.aclweb.org/anthology/D19-1291.pdf" title="Title">
[pdf] </a>
<a href="https://github.com/tuhinjubcse/AMPERSAND-EMNLP2019" title="Title">
[Code and Data] </a>
<a href="https://github.com/tuhinjubcse/tuhinjubcse.github.io/blob/master/AMPERSAND_%20Argument%20Mining%20for%20PERSuAsive%20oNline%20%20Discussions-SM.pdf" title="Title">
  [Slides]</a></p>

<p> 2) <b> Discourse Relation Prediction: Revisiting Word Pairs with Convolutional Networks ,   </b> <br>
  In 20th Annual Meeting of the Special Interest Group on Discourse and Dialogue (SIGDIAL 2019),Stockholm, Sweden
  Siddharth Varia  ,Christopher Hidey, <b>Tuhin Chakrabarty </b>.
  <br> ORAL PRESENTATION (Acceptance Rate : 35%)
 <a href="https://www.aclweb.org/anthology/W19-5951.pdf" title="Title">
[pdf] </a> </p>

<p> 3) <b> IMHO Fine Tuning Improves Claim Detection</b> <br>
In Proceedings of NAACL-HLT 2019 ,Minneapolis, USA, June 2019. <br>  
 <b> Tuhin Chakrabarty </b> ,Christopher Hidey , Kathy Mckeown . <br>  
 ORAL PRESENTATION (Acceptance Rate Oral : 10.8% [72 out of 666 submitted papers])
<a href="https://www.aclweb.org/anthology/N19-1054.pdf" title="Title">
[pdf] </a>
<a href="https://github.com/tuhinjubcse/tuhinjubcse.github.io/blob/master/IMHO%20Fine-Tuning%20Improves%20Claim%20Detection%20.pdf" title="Title">
 [Slides] </a> 
  <a href="https://github.com/tuhinjubcse/IMHO-NAACL2019" title="Title">
[Code and Data] </a>
</p>


## FACT CHECKING

<p> 1) <b> The Answer is Language Model Fine-tuning </b> <br>
 In Proceedings of the 13th International Workshop on Semantic Evaluation , NAACL-HLT , Minneapolis, USA, June 2019  <br> 
 <b> Tuhin Chakrabarty </b> ,Smaranda Muresan .   4th and 2nd place in SUBTASK A & B respectively 
<a href="https://www.aclweb.org/anthology/S19-2200.pdf" title="Title">
[pdf] </a> </p>

<p> 2) <b>Robust Document Retrieval and Individual Evidence Modeling for Fact Extraction and Verification </b> <br>
 In Proceedings of the First Workshop on Fact Extraction and VERification (FEVER) ,EMNLP ,Brussels ,2018  <br> 
 <b> Tuhin Chakrabarty </b> ,Tariq Alhindi , Smaranda Muresan :- <a href="http://aclweb.org/anthology/W18-5521.pdf" title="Title"> [pdf] </a> <a href="https://github.com/tuhinjubcse/FEVER-EMNLP" title="Title">
[Code] </a>.</p>


## OTHER WORK 


 <p> 1) <b> Pay "Attention'' to your Context when Classifying Abusive Language</b> <br>
In Proceedings of 3rd Abusive Language Workshop ,ACL 2019  Florence, Italy. <br>  
 <b> Tuhin Chakrabarty </b> ,Kilol Gupta, Smaranda Muresan .
 <a href="https://www.aclweb.org/anthology/W19-3508.pdf" title="Title">
[pdf] </a> <a href="https://github.com/tuhinjubcse/ALW3-ACL2019" title="Title">
[Code] </a> </p>



## CONTACT ME
Email : <br/>
tuhinc@isi.edu (ISI) <br/>
        tuhincha@usc.edu (USC)<br/>
        tuhin.chakrabarty@columbia.edu(COLUMBIA)<br/>
        tuhinjubcse@gmail.com(PERSONAL GMAIL) <br/>
Mobile : +13476306405
 
<!-- Please don't remove this: Grab your social icons from https://github.com/carlsednaoui/gitsocial -->

<!-- display the social media buttons in your README -->

[![alt text][1.1]][1]
[![alt text][2.1]][2]
[![alt text][6.1]][6]


<!-- links to social media icons -->
<!-- no need to change these -->

<!-- icons with padding -->

[1.1]: http://i.imgur.com/tXSoThF.png (twitter icon with padding)
[2.1]: http://i.imgur.com/P3YfQoD.png (facebook icon with padding)
[6.1]: http://i.imgur.com/0o48UoR.png (github icon with padding)

<!-- icons without padding -->

[1.2]: http://i.imgur.com/wWzX9uB.png (twitter icon without padding)
[2.2]: http://i.imgur.com/fep1WsG.png (facebook icon without padding)
[6.2]: http://i.imgur.com/9I6NRUm.png (github icon without padding)


<!-- links to your social media accounts -->
<!-- update these accordingly -->

[1]: https://twitter.com/Tuhin66978276
[2]: https://www.facebook.com/tuhin.chakrabarty
[6]: https://github.com/tuhinjubcse

<!-- Please don't remove this: Grab your social icons from https://github.com/carlsednaoui/gitsocial -->


## NON NLP LIFE
When not doing NLP, I love reading.I love Morissey and The Smiths and feel they are the best band in the world :). I also love taking pictures. See my photography trail on my instagram handle (@bonginnyc). I also  sometimes write on love and longing <a href="https://bonginnyc.blogspot.com" title="Title"> Tuhins blog </a>
